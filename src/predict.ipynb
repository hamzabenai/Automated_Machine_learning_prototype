{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98d76646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import logging\n",
    "from typing import Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss, TomekLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import ClassifierMixin, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "\n",
    "class DataStrategy(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def handle_data(self, data : pd.DataFrame, target: str) -> Union[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "      pass\n",
    "\n",
    "class RemoveIdentifierStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      if data is not None and target in data.columns:\n",
    "        for column in data.columns:\n",
    "          if data[column].nunique() == 1 or data[column].nunique() == len(data):\n",
    "            data = data.drop(columns=[column])\n",
    "        return data\n",
    "      else:\n",
    "        raise ValueError(\"Remove Identifier Strategy Error : Data is None or target column is missing.\")\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error removing identifier columns: {e}\")\n",
    "      raise\n",
    "    \n",
    "class MissingValueStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      if data is not None and target in data.columns:\n",
    "        for column in data.columns:\n",
    "          count_nan = data[column].isnull().sum()\n",
    "          if len(data) <= 2000:\n",
    "            if data[column].dtype in ['object', 'category']:\n",
    "              data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "            else:\n",
    "              data[column].fillna(data[column].mean(), inplace=True)\n",
    "          elif len(data) >= 2000 and count_nan < 0.2 * len(data):\n",
    "            data = data.dropna(subset=[column])\n",
    "          else:\n",
    "            data = data.drop(columns=[column])\n",
    "        logging.info(\"Missing values handled successfully.\")\n",
    "        return data\n",
    "      elif data is None or target not in data.columns:\n",
    "        raise ValueError(\"Missing values Strategy Error : Data is None or target column is missing.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error handling missing values: {e}\")\n",
    "        raise\n",
    "\n",
    "class OutlierStrategy(DataStrategy): \n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      if data is not None and target in data.columns:\n",
    "        original_rows = len(data)\n",
    "        logging.info(f\"Original number of rows: {original_rows}\")\n",
    "        if len(data) <= 2000:\n",
    "          numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "          mask = pd.Series(True, index=data.index)\n",
    "          \n",
    "          for column in numeric_cols:\n",
    "            q1 = data[column].quantile(0.25)\n",
    "            q3 = data[column].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            col_mask = (data[column] >= lower_bound) & (data[column] <= upper_bound)\n",
    "            mask &= col_mask\n",
    "          data = data[mask]\n",
    "          if data is None or data.empty:\n",
    "            raise ValueError(\"Outlier Strategy Error : IQR method, No data left after outlier removal.\")\n",
    "        elif 2000 < len(data) <= 10000:\n",
    "          lof = LocalOutlierFactor(n_neighbors=20)\n",
    "          outliers = lof.fit_predict(data.select_dtypes(include=[np.number]))\n",
    "          data = data[outliers == 1]\n",
    "          if data is None or data.empty:\n",
    "            raise ValueError(\"Outlier Strategy Error : Local Factor method, No data left after outlier removal.\")\n",
    "        else:\n",
    "          numeric_data = data.select_dtypes(include=[np.number])\n",
    "          iso_forest = IsolationForest(contamination='auto',\n",
    "                                    random_state=42,\n",
    "                                    n_estimators=100)\n",
    "          outliers = iso_forest.fit_predict(numeric_data)\n",
    "          data = data[outliers == 1]\n",
    "          if data is None or data.empty:\n",
    "            raise ValueError(\"Outlier Strategy Error : Isolation Forest method, No data left after outlier removal.\")\n",
    "        \n",
    "        logging.info(\"Outliers handled successfully.\")\n",
    "        logging.info(f\"Removed {original_rows - len(data)} rows ({((original_rows - len(data))/original_rows):.1%})\")\n",
    "        return data\n",
    "      else:\n",
    "        raise ValueError(\"Outlier Strategy Error : Data is None or target column is missing.\")\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error handling outliers: {e}\")\n",
    "      raise\n",
    "    \n",
    "class ImbalancedDataStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      data_size = None\n",
    "      if len(data) <= 2000:\n",
    "        data_size = \"small\"\n",
    "      elif 2000 < len(data) <= 20000:\n",
    "        data_size = \"medium\"\n",
    "      else: \n",
    "        data_size = \"large\"\n",
    "      class_counts = Counter(data[target])\n",
    "      perform_test = False\n",
    "      for class_value, count in class_counts.items():\n",
    "        if count >= 0.75 * len(data):\n",
    "          perform_test = True\n",
    "          break\n",
    "      if perform_test:\n",
    "        X = data.drop(columns=[target])\n",
    "        y = data[target]\n",
    "        logging.warning(f\"Class {class_value} is a majority class with {count/len(data)*100}% of the total records.\")\n",
    "        if data_size == \"small\":\n",
    "          ada = ADASYN(sampling_strategy='minority', n_neighbors=3)\n",
    "          X_res, y_res = ada.fit_resample(X, y)\n",
    "          data = pd.concat([X_res, y_res], axis=1)\n",
    "        elif data_size == \"medium\":\n",
    "          smote_tomek = SMOTETomek(sampling_strategy='auto', tomek=TomekLinks(sampling_strategy='majority'))\n",
    "          X_res, y_res = smote_tomek.fit_resample(X, y)\n",
    "          data = pd.concat([X_res, y_res], axis=1)\n",
    "        else:\n",
    "          nm = NearMiss(version=3, n_jobs=-1)  \n",
    "          X_res, y_res = nm.fit_resample(X, y)\n",
    "          data = pd.concat([X_res, y_res], axis=1)\n",
    "        logging.info(\"Imbalanced data handled successfully.\")\n",
    "      return data\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error handling imbalanced data: {e}\")\n",
    "      raise\n",
    "\n",
    "class SplitDataStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    try:\n",
    "      x_train, x_test, y_train, y_test = train_test_split(data.drop(columns=[target]), \n",
    "                                                        data[target], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "      logging.info(\"Data split into training and testing sets successfully.\")\n",
    "      return x_train, x_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error splitting data: {e}\")\n",
    "      raise\n",
    "\n",
    "class ScaleDataStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      X = data.drop(columns=[target])\n",
    "      y = data[target]\n",
    "      scaler = RobustScaler()\n",
    "      X_scaled = scaler.fit_transform(X)\n",
    "      scaled_data = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "      scaled_data[target] = y.reset_index(drop=True)\n",
    "      logging.info(\"Data scaled successfully.\")\n",
    "      return scaled_data\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error scaling data: {e}\")\n",
    "      raise\n",
    "    \n",
    "class EncodeDataStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      X = data.drop(columns=[target])\n",
    "      y = data[target]\n",
    "      categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "      \n",
    "      # Encode features\n",
    "      for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "      \n",
    "      # Encode target variable\n",
    "      if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y)\n",
    "        y_encoded = pd.Series(y_encoded, name=target, index=y.index)  # Keep original index\n",
    "      else:\n",
    "        y_encoded = y\n",
    "      \n",
    "      X[target] = y_encoded\n",
    "      logging.info(\"Data encoded successfully.\")\n",
    "      return X\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error encoding data: {e}\")\n",
    "      raise\n",
    "  \n",
    "class FeatureSelectionStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      X = data.drop(columns=[target])\n",
    "      y = data[target]\n",
    "      if pd.api.types.is_categorical_dtype(y) or not pd.api.types.is_numeric_dtype(y):\n",
    "        mi = mutual_info_classif(X, y, random_state=42)\n",
    "      else:\n",
    "          mi = mutual_info_regression(X, y, random_state=42)\n",
    "      threshold = max(0.1, np.percentile(mi, 50))\n",
    "      selected = mi >= threshold\n",
    "      if not any(selected): \n",
    "          selected = mi >= mi.max()\n",
    "      X_filtered = X.loc[:, selected]\n",
    "      logging.info(f\"Selected {X_filtered.shape[1]} features with threshold {threshold:.3f}\")\n",
    "      return pd.concat([X_filtered, y], axis=1)\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Feature selection failed, returning original data. Error: {e}\")\n",
    "      return data \n",
    "\n",
    "# class FeatureEngineeringStrategy(DataStrategy):\n",
    "#   def handle_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     pass\n",
    "\n",
    "class DimensionalityReductionStrategy(DataStrategy):\n",
    "  def handle_data(self, data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    try:\n",
    "      X = data.drop(columns=[target])\n",
    "      y = data[target]\n",
    "      pca = PCA(n_components=0.95, random_state=42)\n",
    "      X_reduced = pca.fit_transform(X)\n",
    "      reduced_data = pd.DataFrame(X_reduced, columns=[f'PC{i+1}' for i in range(X_reduced.shape[1])])\n",
    "      reduced_data[target] = y.reset_index(drop=True)\n",
    "      logging.info(\"Dimensionality reduction applied successfully.\")\n",
    "      return reduced_data\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error applying dimensionality reduction: {e}\")\n",
    "      raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24f4f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_identifiers(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = RemoveIdentifierStrategy().handle_data(data, target)\n",
    "    logging.info(\"Identifiers removed successfully.\")\n",
    "    return data\n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error removing identifiers: {e}\")\n",
    "    raise RuntimeError(f\"Error in removing identifiers: {e}\") \n",
    "  \n",
    "def fill_missing_values(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = MissingValueStrategy().handle_data(data, target)\n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in filling missing values: {e}\")\n",
    "  \n",
    "def remove_outliers(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = OutlierStrategy().handle_data(data, target)\n",
    "    \n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in removing outliers: {e}\")\n",
    "  \n",
    "def encode_data(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = EncodeDataStrategy().handle_data(data, target)\n",
    "    \n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in encoding data: {e}\")\n",
    "  \n",
    "def scale_data(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = ScaleDataStrategy().handle_data(data, target)\n",
    "    \n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in scaling data: {e}\")\n",
    "  \n",
    "def select_features(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = FeatureSelectionStrategy().handle_data(data, target)\n",
    "    \n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in feature selection: {e}\")\n",
    "  \n",
    "def reduce_dimensions(data: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "  try:\n",
    "    data = DimensionalityReductionStrategy().handle_data(data, target)\n",
    "    \n",
    "    return data\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in dimensionality reduction: {e}\")\n",
    "  \n",
    "def split_data(data: pd.DataFrame, target: str, test_size: float = 0.2, random_state: int = 42) -> tuple: \n",
    "  try:\n",
    "    x_train, x_test, y_train, y_test = SplitDataStrategy().handle_data(data, target)\n",
    "    logging.info('data shape after splitting: x_train: {}, y_train: {}, x_test: {}, y_test: {}'.format(\n",
    "      x_train.shape, y_train.shape, x_test.shape, y_test.shape))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "  except Exception as e:\n",
    "    raise RuntimeError(f\"Error in splitting data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20ab543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0  87524       442.246011       253.291155      0.819738       90546   \n",
       "1  75166       406.690687       243.032436      0.801805       78789   \n",
       "2  90856       442.267048       266.328318      0.798354       93717   \n",
       "3  45928       286.540559       208.760042      0.684989       47336   \n",
       "4  79408       352.190770       290.827533      0.564011       81463   \n",
       "\n",
       "     Extent  Perimeter    Class  \n",
       "0  0.758651   1184.040  Kecimen  \n",
       "1  0.684130   1121.786  Kecimen  \n",
       "2  0.637613   1208.575  Kecimen  \n",
       "3  0.699599    844.162  Kecimen  \n",
       "4  0.792772   1073.251  Kecimen  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('H:\\DATA\\MY\\Projects\\supervised_learning_prediction_Saas\\data\\Raisin_Dataset.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "289175ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mouncef\\AppData\\Local\\Temp\\ipykernel_7428\\2082418945.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n",
      "C:\\Users\\mouncef\\AppData\\Local\\Temp\\ipykernel_7428\\2082418945.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\mouncef\\AppData\\Local\\Temp\\ipykernel_7428\\2082418945.py:205: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(y) or not pd.api.types.is_numeric_dtype(y):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvexArea    0\n",
       "Class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('H:\\DATA\\MY\\Projects\\supervised_learning_prediction_Saas\\data\\Raisin_Dataset.xlsx')\n",
    "data = remove_identifiers(data, 'Class')\n",
    "data = fill_missing_values(data, 'Class')\n",
    "data = remove_outliers(data, 'Class')\n",
    "data = encode_data(data, 'Class')\n",
    "data = scale_data(data, 'Class')\n",
    "\n",
    "data = select_features(data, 'Class')\n",
    "x_train, x_test, y_train, y_test = split_data(data, 'Class')\n",
    "data.isnull().sum()  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e604ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6c72b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172,)\n",
      "(172,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4ffb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'f1_score': f1_score(y_test, y_pred, average='weighted'),  # Automatically set to 'weighted' for multi-class\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "    'mean_cross_val_score': cross_val_score(model, x_test, y_test, \n",
    "                                             cv=5, scoring='accuracy').mean(),\n",
    "    'cross_val_scores': cross_val_score(model, x_test, y_test, \n",
    "                                        cv=5, scoring='accuracy')\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
